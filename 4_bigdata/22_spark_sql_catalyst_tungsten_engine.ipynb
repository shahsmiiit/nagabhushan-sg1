{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499d5de6",
   "metadata": {},
   "source": [
    "# Spark SQL Catalyst Optimizer and Tungsten Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fa51d",
   "metadata": {},
   "source": [
    "## Catalyst Optimizer\n",
    "\n",
    "![Catalyst Optimizer Overview](../images/catalyst_overview.png)\n",
    "\n",
    "### Definition\n",
    "The **Catalyst Optimizer** is a key component of **Spark SQL** responsible for optimizing the execution plans of **DataFrame** and **Dataset** operations.\n",
    "\n",
    "### Role in Spark SQL\n",
    "Catalyst acts as a **query planner** that transforms **logical plans** into **optimized physical plans**, ensuring queries execute efficiently.\n",
    "\n",
    "### Phases of Optimization \n",
    "\n",
    "- **Analysis**\n",
    "  - Resolves column names, table names, and functions.\n",
    "  - Generates an **AST (Abstract Syntax Tree)** and checks for errors (missing columns, incorrect data types).\n",
    "\n",
    "- **Logical Optimization**\n",
    "  - Applies **rule-based transformations** such as:\n",
    "    - predicate pushdown\n",
    "    - projection pruning\n",
    "    - constant folding\n",
    "    - boolean expression simplification\n",
    "  - Goal: reduce the data processed early.\n",
    "\n",
    "- **Physical Planning**\n",
    "  - Chooses the best physical plan considering:\n",
    "    - data distribution\n",
    "    - join strategies\n",
    "    - available resources\n",
    "    \n",
    "- **Code Generation (Whole-Stage Code Generation)**\n",
    "  - Introduced as part of Project Tungsten.\n",
    "  - Generates optimized Java bytecode to minimize CPU and memory overhead.\n",
    "\n",
    "### Why it improves performance\n",
    "Catalyst helps by:\n",
    "- reducing the amount of data processed\n",
    "- minimizing operations and complexity\n",
    "- using resources (CPU/memory) more efficiently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92f114",
   "metadata": {},
   "source": [
    "### Example: See Catalyst Plans Using `explain()`\n",
    "\n",
    "We will create a small “orders” dataset and run a query with filter + select + aggregation.  \n",
    "Then we will use `explain(True)` to view:\n",
    "- the logical plan\n",
    "- the optimized logical plan\n",
    "- the physical plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64166f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, broadcast\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkSQL-Internals-Demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5db3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [\n",
    "    (1, \"IN\", \"Electronics\", 1200.0),\n",
    "    (2, \"IN\", \"Grocery\",      250.0),\n",
    "    (3, \"US\", \"Electronics\",  999.0),\n",
    "    (4, \"IN\", \"Electronics\",  450.0),\n",
    "    (5, \"US\", \"Grocery\",      300.0),\n",
    "    (6, \"IN\", \"Grocery\",      150.0),\n",
    "]\n",
    "df_orders = spark.createDataFrame(orders, [\"order_id\", \"country\", \"category\", \"amount\"])\n",
    "\n",
    "query_df = (\n",
    "    df_orders\n",
    "    .filter(col(\"country\") == \"IN\")\n",
    "    .select(\"category\", \"amount\")\n",
    "    .groupBy(\"category\")\n",
    "    .agg(F.sum(\"amount\").alias(\"total_amount\"))\n",
    ")\n",
    "\n",
    "query_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d49be",
   "metadata": {},
   "source": [
    "## Tungsten Engine (Execution Engine)\n",
    "\n",
    "The **Tungsten execution engine** focuses on **low-level optimizations** for:\n",
    "- memory management\n",
    "- CPU utilization\n",
    "\n",
    "### How it works with Catalyst\n",
    "- **Catalyst** handles **high-level query planning** (logical → optimized physical plan).\n",
    "- **Tungsten** focuses on **efficient execution** of that plan.\n",
    "- Together, they enable Spark to execute queries with maximum efficiency.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
