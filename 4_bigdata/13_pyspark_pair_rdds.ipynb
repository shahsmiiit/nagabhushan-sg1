{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc60c47a",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this notebook, we will:\n",
    "- Load **orders.csv** and **customers.csv** into RDDs\n",
    "- Transform each dataset into **key-value pairs**\n",
    "- Perform a key-based operation to find customers who **haven’t placed any orders**\n",
    "\n",
    "This example demonstrates how to use **map()**, **split()**, and **subtractByKey()** transformations in PySpark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb89e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersDataPath = 'orders.csv'\n",
    "ordersRdd = spark.sparkContext.textFile(ordersDataPath)\n",
    "\n",
    "for i in ordersRdd.take(10): \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeaeee3",
   "metadata": {},
   "source": [
    "### Step 1: Inspect the first record\n",
    "Retrieve the first record from the RDD for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b678e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ordersRdd.first()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c770710",
   "metadata": {},
   "source": [
    "### Step 2: Split the record\n",
    "Split the record into columns using the comma as a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9a689",
   "metadata": {},
   "source": [
    "### Step 3: Extract customer ID\n",
    "Extract the third field (index 2) which represents the customer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.split(',')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497804f",
   "metadata": {},
   "source": [
    "### Step 4: Convert to integer\n",
    "Convert the extracted customer ID into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(x.split(',')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de5ebc",
   "metadata": {},
   "source": [
    "### Step 5: Create a key-value pair\n",
    "Represent the data as a tuple `(custId, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(int(x.split(',')[2]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20823e",
   "metadata": {},
   "source": [
    "### Step 6: Define a lambda transformation\n",
    "Create a lambda function that performs this transformation for all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: (int(x.split(',')[2]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b03bd",
   "metadata": {},
   "source": [
    "### Step 7: Apply transformation\n",
    "Apply the lambda function across the RDD to generate key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb62ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersMapRdd = ordersRdd.map(lambda x: (int(x.split(',')[2]), 1))\n",
    "for i in ordersMapRdd.take(10): \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf893f1",
   "metadata": {},
   "source": [
    "### Step 8: Load and transform customers.csv\n",
    "Generate key-value pairs where the key is the customer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersDataPath = 'customers.csv'\n",
    "customersRdd = spark.sparkContext.textFile(customersDataPath)\n",
    "\n",
    "customersMapRdd = customersRdd.map(lambda x: (int(x.split(',')[0]), 1))\n",
    "for i in customersMapRdd.take(10): \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ea52a",
   "metadata": {},
   "source": [
    "### Step 9: Find customers without orders\n",
    "Use `subtractByKey()` to find customers who are present in the customer list but missing from orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9424ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find customers who haven’t placed any orders\n",
    "customersMapRdd.subtractByKey(ordersMapRdd).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7b434",
   "metadata": {},
   "source": [
    "### Step 10: Final Compact Version\n",
    "Here we combine all transformations into a single, clean version for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c281fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact version combining all steps\n",
    "ordersRdd = spark.sparkContext.textFile('orders.csv')\n",
    "customersRdd = spark.sparkContext.textFile('customers.csv')\n",
    "\n",
    "ordersMapRdd = ordersRdd.map(lambda x: (int(x.split(',')[2]), 1))\n",
    "customersMapRdd = customersRdd.map(lambda x: (int(x.split(',')[0]), 1))\n",
    "\n",
    "result = customersMapRdd.subtractByKey(ordersMapRdd).collect()\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
