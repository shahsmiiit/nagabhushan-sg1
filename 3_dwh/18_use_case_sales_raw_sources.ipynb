{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea203c1",
   "metadata": {},
   "source": [
    "# Section 1: Raw Sales Sources "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2aa44",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "An organization receives **sales transactions** from **two independent raw sources**.  \n",
    "Both sources provide the same set of fields, but they are ingested into separate raw tables so that:\n",
    "- the original incoming data is preserved as-is, and\n",
    "- each source can be audited independently using load metadata.\n",
    "\n",
    "The raw data is stored in a MySQL database named **`source_db`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489c5b2",
   "metadata": {},
   "source": [
    "## Raw Source Tables\n",
    "\n",
    "The database contains two raw tables:\n",
    "\n",
    "1. **`sales_raw_source1`**  \n",
    "2. **`sales_raw_source2`**\n",
    "\n",
    "Both tables have an identical structure and represent **sales transaction records**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8710f4",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "Each raw sales record includes:\n",
    "\n",
    "- **order_id** *(VARCHAR(20))*  \n",
    "  Identifier of the order/transaction (not guaranteed to be unique unless enforced separately).\n",
    "\n",
    "- **customer_name** *(VARCHAR(100))*  \n",
    "  Name of the customer who placed the order.\n",
    "\n",
    "- **city** *(VARCHAR(50))*  \n",
    "  Customer’s city.\n",
    "\n",
    "- **email** *(VARCHAR(100))*  \n",
    "  Customer’s email address.\n",
    "\n",
    "- **product_name** *(VARCHAR(100))*  \n",
    "  Name of the product sold.\n",
    "\n",
    "- **product_category** *(VARCHAR(50))*  \n",
    "  Category of the product.\n",
    "\n",
    "- **sale_date** *(DATE)*  \n",
    "  Date on which the sale occurred.\n",
    "\n",
    "- **quantity** *(INT)*  \n",
    "  Number of units purchased in the record.\n",
    "\n",
    "- **unit_price** *(DECIMAL(10,2))*  \n",
    "  Price per unit.\n",
    "\n",
    "- **load_timestamp** *(TIMESTAMP)*  \n",
    "  Timestamp indicating when this record was loaded/ingested into the raw table (useful for auditing and incremental loads).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46602c75",
   "metadata": {},
   "source": [
    "### Problem to Solve\n",
    "\n",
    "You are given two raw sales sources stored as MySQL tables. Your job is to treat these as **incoming raw feeds** and prepare them for downstream analytics.\n",
    "\n",
    "The requirements are:\n",
    "\n",
    "1. **Store** each source independently in raw tables (`sales_raw_source1`, `sales_raw_source2`).\n",
    "2. **Preserve** the original incoming fields without modification.\n",
    "3. **Track** ingestion time using `load_timestamp` for auditability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c196",
   "metadata": {},
   "source": [
    "## Source Verify\n",
    "\n",
    "Validate row counts and preview a few rows from each source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a215d",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT 'source1' AS src, COUNT(*) AS rows_count FROM source_db.sales_raw_source1\n",
    "UNION ALL\n",
    "SELECT 'source2' AS src, COUNT(*) AS rows_count FROM source_db.sales_raw_source2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029069f",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM source_db.sales_raw_source1 ORDER BY load_timestamp, order_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6f116",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM source_db.sales_raw_source2 ORDER BY load_timestamp, order_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3cb3a",
   "metadata": {},
   "source": [
    "# Section 2 - Build the Bronze Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6404b7",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "The goal of the **Bronze layer** is to act as the **raw landing layer inside the DWH**, where incoming sales data is captured in its original form, with minimal transformation.\n",
    "\n",
    "In this simplified training pipeline:\n",
    "- Sales data arrives from **two operational source tables** in `source_db`\n",
    "- Both sources have the same structure but represent different **source systems**\n",
    "- The Bronze layer **merges** both sources into **one consolidated Bronze table**\n",
    "- To keep the flow easy to teach, Bronze uses a **full load** pattern:\n",
    "  - `TRUNCATE` the Bronze table\n",
    "  - `INSERT` fresh data from both sources\n",
    "\n",
    "## Raw Source Tables\n",
    "\n",
    "Bronze reads raw sales records from these two source tables:\n",
    "\n",
    "1. `source_db.sales_raw_source1`  \n",
    "2. `source_db.sales_raw_source2`\n",
    "\n",
    "In Bronze, these sources are tagged using a `source_system` column:\n",
    "- `flipkart` → records from `sales_raw_source1`\n",
    "- `amazon` → records from `sales_raw_source2`\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "Bronze stores consolidated raw records in: `bronze_db.bronze_sales_raw`\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `source_system` | Identifies the source system of the record (`flipkart` or `amazon`). |\n",
    "| `order_id` | Business order identifier for the transaction. |\n",
    "| `customer_name` | Customer name captured in the raw feed. |\n",
    "| `city` | Customer city from the raw feed (may be NULL or inconsistent). |\n",
    "| `email` | Customer email as received (may contain invalid formats). |\n",
    "| `product_name` | Product name sold in the transaction. |\n",
    "| `product_category` | Product category from the raw feed. |\n",
    "| `sale_date` | Date of the sale transaction. |\n",
    "| `quantity` | Units purchased in the transaction. |\n",
    "| `unit_price` | Price per unit for the item. |\n",
    "| `load_timestamp` | Timestamp when the record was loaded into the source table (audit field). |\n",
    "\n",
    "## Problems to Solve in Bronze\n",
    "\n",
    "Implement the Bronze ingestion layer with the following requirements:\n",
    "\n",
    "1. **Create the Bronze database and table**\n",
    "   - Database: `bronze_db`\n",
    "   - Table: `bronze_sales_raw`\n",
    "\n",
    "2. **Consolidate both source tables into one Bronze table**\n",
    "   - Load all records from `source_db.sales_raw_source1` and tag them as `source_system = 'flipkart'`\n",
    "   - Load all records from `source_db.sales_raw_source2` and tag them as `source_system = 'amazon'`\n",
    "\n",
    "3. **Use a full refresh strategy (full load)**\n",
    "   - `TRUNCATE` the Bronze table before every load run\n",
    "   - Re-load data using `INSERT INTO ... SELECT ...` from both sources\n",
    "\n",
    "4. **Preserve raw data as-is**\n",
    "   - Do not cleanse, standardize, or deduplicate in Bronze\n",
    "   - The only enrichment allowed is adding `source_system` for traceability\n",
    "\n",
    "5. **Support traceability and auditability**\n",
    "   - Keep `load_timestamp` intact to support later analysis on ingestion timing and data freshness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aabc7a",
   "metadata": {},
   "source": [
    "## Bronze Verify\n",
    "\n",
    "Check how many rows came from each source and preview the merged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a8258",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT source_system, COUNT(*) AS rows_count\n",
    "FROM bronze_db.bronze_sales_raw\n",
    "GROUP BY source_system;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47b8aa",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM bronze_db.bronze_sales_raw ORDER BY load_timestamp, source_system, order_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46de2f",
   "metadata": {},
   "source": [
    "# Section 3 - Build the Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071292b",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "The purpose of the **Silver layer** is to store **cleansed and standardized** sales data.\n",
    "\n",
    "Silver reads consolidated raw records from the Bronze table (`bronze_db.bronze_sales_raw`) and applies business cleansing rules before writing to a curated Silver table.\n",
    "\n",
    "In this simplified training pipeline, Silver performs three key actions:\n",
    "1. **Standardizes city values** (business standardization)\n",
    "2. **Filters out records that should not be promoted** (business rule example: exclude Business plans to stop selling `Beauty` products, and they need not be appearing in the analytics)\n",
    "3. **Deduplicates records by `order_id`** (keeps the latest row based on `load_timestamp`)\n",
    "\n",
    "## Input Table\n",
    "\n",
    "Silver reads from:\n",
    "\n",
    "- `bronze_db.bronze_sales_raw`\n",
    "\n",
    "This table contains raw consolidated records from multiple source systems, along with `load_timestamp` for auditability.\n",
    "\n",
    "## Output Table\n",
    "\n",
    "Silver writes cleansed records into:\n",
    "\n",
    "- `silver_db.silver_sales_clean`\n",
    "\n",
    "This table enforces **one row per `order_id`** using:\n",
    "- `order_id` as the **PRIMARY KEY**\n",
    "- deduplication logic during load to ensure uniqueness\n",
    "\n",
    "## Data Dictionary (Silver Output Table)\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `order_id` | Unique order identifier in Silver (PRIMARY KEY). |\n",
    "| `source_system` | Source system from Bronze (e.g., `flipkart`, `amazon`). |\n",
    "| `customer_name` | Customer name as received from Bronze. |\n",
    "| `city` | Standardized city value after Silver cleansing rules. |\n",
    "| `email` | Email after trimming spaces (basic standardization). |\n",
    "| `product_name` | Product name sold. |\n",
    "| `product_category` | Product category (excluding `Beauty` in Silver). |\n",
    "| `sale_date` | Date of sale transaction. |\n",
    "| `quantity` | Units purchased. |\n",
    "| `unit_price` | Price per unit. |\n",
    "| `load_timestamp` | Timestamp representing the latest ingested version of the record kept in Silver. |\n",
    "\n",
    "## Problems to Solve in Silver\n",
    "\n",
    "Implement the Silver layer with the following requirements:\n",
    "\n",
    "1. **Create the Silver database and curated table**\n",
    "   - Database: `silver_db`\n",
    "   - Table: `silver_sales_clean`\n",
    "\n",
    "2. **Standardize city values**\n",
    "   Apply the following business rules for `city`:\n",
    "   - If `city` is **NULL**, **blank**, or equals the string **`null`** (case-insensitive), default it to **`Delhi`**\n",
    "   - If `city` is `NY`, standardize it to **`New York`**\n",
    "   - If `city` is `Hyd` or `HYD` (case variations), standardize it to **`Hyderabad`**\n",
    "   - Otherwise, store the trimmed city value\n",
    "\n",
    "3. **Standardize email values**\n",
    "   - Apply `TRIM(email)` to remove leading/trailing spaces\n",
    "\n",
    "4. **Filter out records not eligible for promotion**\n",
    "   - Remove rows where `product_category = 'Beauty'`\n",
    "   - Keep rows where `product_category` is NULL or not equal to `Beauty`\n",
    "\n",
    "5. **Deduplicate by `order_id`**\n",
    "   - If multiple rows share the same `order_id`, keep **only the latest record** based on `load_timestamp`\n",
    "   - Use a window function such as:\n",
    "     - `ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY load_timestamp DESC)`\n",
    "\n",
    "6. **Use a full refresh strategy (full load)**\n",
    "   - `TRUNCATE` the Silver table before each load run\n",
    "   - Reload the cleansed, filtered, deduplicated dataset from Bronze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ece90",
   "metadata": {},
   "source": [
    "## Silver Verify\n",
    "\n",
    "Validate row counts and inspect the cleaned output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e5138",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT COUNT(*) AS silver_rows FROM silver_db.silver_sales_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f2441",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT COUNT(*) AS missing_city_after_cleaning\n",
    "FROM silver_db.silver_sales_clean\n",
    "WHERE city IS NULL OR TRIM(city) = '';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b9302",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT COUNT(*) AS beauty_rows_in_silver\n",
    "FROM silver_db.silver_sales_clean\n",
    "WHERE product_category = 'Beauty';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03adb37",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM silver_db.silver_sales_clean ORDER BY load_timestamp, order_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63d359",
   "metadata": {},
   "source": [
    "# Section 4 - Build the Gold Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927adb4e",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "The purpose of the **Gold layer** is to store **business-ready, analytics-friendly** data that supports reporting and BI use cases.\n",
    "\n",
    "In this pipeline, the Gold layer models the cleansed Silver data into a **simple star schema** with:\n",
    "- `dim_customer`\n",
    "- `dim_product`\n",
    "- `fact_sales`\n",
    "\n",
    "- Customer is uniquely identified by **email**\n",
    "- If the same email appears with different attributes over time, keep the **latest** version using `load_timestamp`\n",
    "- The fact table stores a derived measure:  \n",
    "  `total_amount = quantity * unit_price`\n",
    "\n",
    "## Input Table\n",
    "\n",
    "Gold reads from:\n",
    "\n",
    "- `silver_db.silver_sales_clean`\n",
    "\n",
    "This table already contains cleansed and deduplicated sales records (one row per `order_id`).\n",
    "\n",
    "## Star Schema Tables (Gold Output)\n",
    "\n",
    "Gold writes into these three tables in `gold_db`:\n",
    "\n",
    "1. **Customer Dimension**: `gold_db.dim_customer`  \n",
    "2. **Product Dimension**: `gold_db.dim_product`  \n",
    "3. **Sales Fact**: `gold_db.fact_sales`\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "### `dim_customer`\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `customer_key` | Surrogate key (AUTO_INCREMENT PRIMARY KEY). |\n",
    "| `email` | Natural key for customer (UNIQUE). |\n",
    "| `customer_name` | Latest known customer name for the email. |\n",
    "| `city` | Latest known city for the email. |\n",
    "| `last_seen_ts` | Latest `load_timestamp` seen for the email (used to keep the newest record). |\n",
    "\n",
    "### `dim_product`\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `product_key` | Surrogate key (AUTO_INCREMENT PRIMARY KEY). |\n",
    "| `product_name` | Product name. |\n",
    "| `product_category` | Product category. |\n",
    "| `(product_name, product_category)` | Composite natural key (UNIQUE). |\n",
    "\n",
    "### `fact_sales`\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `sales_key` | Surrogate key (AUTO_INCREMENT PRIMARY KEY). |\n",
    "| `order_id` | Business order identifier (UNIQUE). |\n",
    "| `customer_key` | Foreign key to `dim_customer.customer_key`. |\n",
    "| `product_key` | Foreign key to `dim_product.product_key`. |\n",
    "| `sale_date` | Date of sale. |\n",
    "| `quantity` | Units purchased. |\n",
    "| `unit_price` | Price per unit. |\n",
    "| `total_amount` | Derived measure: `ROUND(quantity * unit_price, 2)`. |\n",
    "| `load_timestamp` | Record timestamp carried from Silver (audit field). |\n",
    "\n",
    "## Problems to Solve in Gold\n",
    "\n",
    "Implement the Gold layer with the following requirements:\n",
    "\n",
    "1. **Create the Gold database and star schema tables**\n",
    "   - Database: `gold_db`\n",
    "   - Tables: `dim_customer`, `dim_product`, `fact_sales`\n",
    "\n",
    "2. **Load Customer Dimension (`dim_customer`)**\n",
    "   - Customer is uniquely identified by `email`\n",
    "   - Only load records where `email` is not NULL and not blank after trimming\n",
    "   - If multiple records exist for the same email, keep the **latest** record using:\n",
    "     - `ROW_NUMBER() OVER (PARTITION BY email ORDER BY load_timestamp DESC)`\n",
    "   - Store the latest timestamp in `last_seen_ts`\n",
    "\n",
    "3. **Load Product Dimension (`dim_product`)**\n",
    "   - Product uniqueness is defined by `(product_name, product_category)`\n",
    "   - Insert distinct combinations from Silver\n",
    "   - Only load records where both `product_name` and `product_category` are not NULL\n",
    "\n",
    "4. **Load Sales Fact (`fact_sales`)**\n",
    "   - One fact row per `order_id` (order_id is UNIQUE)\n",
    "   - For each Silver record:\n",
    "     - Look up the matching customer using `email` → `dim_customer.customer_key`\n",
    "     - Look up the matching product using `(product_name, product_category)` → `dim_product.product_key`\n",
    "   - Populate measures and audit fields:\n",
    "     - `total_amount = ROUND(quantity * unit_price, 2)`\n",
    "     - carry forward `load_timestamp`\n",
    "\n",
    "5. **Use a full refresh strategy (full load)**\n",
    "   - `TRUNCATE` `fact_sales`, `dim_customer`, and `dim_product`\n",
    "   - Rebuild dimensions first, then load the fact table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac3d47",
   "metadata": {},
   "source": [
    "## Gold Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1ce61",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT COUNT(*) AS customers FROM gold_db.dim_customer;\n",
    "SELECT COUNT(*) AS products  FROM gold_db.dim_product;\n",
    "SELECT COUNT(*) AS facts     FROM gold_db.fact_sales;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3cccd",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM gold_db.fact_sales ORDER BY sale_date, order_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3b6d7",
   "metadata": {},
   "source": [
    "# Section 5: Analytics on the Gold Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6c78b",
   "metadata": {},
   "source": [
    "## Write queries to answer the following business questions\n",
    "\n",
    "### Revenue by City\n",
    "\n",
    "### Revenue by Category\n",
    "\n",
    "### Daily Revenue Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbe6c9",
   "metadata": {},
   "source": [
    "# Section 6: ETL Testing (Quality Assurance) \n",
    "- Testing reliability of the ETL pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb67193",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "You have a **MySQL-based DWH pipeline** with three layers:\n",
    "\n",
    "- **Bronze**: consolidated raw landing table\n",
    "- **Silver**: cleansed + standardized table (business rules applied)\n",
    "- **Gold**: star schema (`dim_customer`, `dim_product`, `fact_sales`) for analytics\n",
    "\n",
    "To ensure the pipeline is reliable, you are implementing a **QA (Quality Assurance) test framework** that runs validations across Bronze, Silver, and Gold, and stores PASS/FAIL outcomes for each pipeline run in a centralized QA table.\n",
    "\n",
    "Each execution of the QA suite generates a unique `test_run_id` (timestamp-based) so that all test results from that run can be grouped and audited.\n",
    "- To get test_run_id, use the statement `SET @test_run_id = DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s');`\n",
    "\n",
    "## Input Table\n",
    "\n",
    "QA checks read from the following DWH tables:\n",
    "\n",
    "- `bronze_db.bronze_sales_raw`\n",
    "- `silver_db.silver_sales_clean`\n",
    "- `gold_db.fact_sales`\n",
    "\n",
    "QA results are written into:\n",
    "\n",
    "- `qa_db.test_results`\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "### `qa_db.test_results`\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `test_run_id` | Unique identifier for a single run of the QA suite (e.g., `YYYYMMDD_HHMMSS`). |\n",
    "| `test_name` | Name of the validation being executed. |\n",
    "| `status` | PASS/FAIL outcome of the test. |\n",
    "| `actual_value` | Numeric value produced by the test (typically a count of rule violations). |\n",
    "| `expected_desc` | Human-readable description of what is expected (e.g., “0 expected”). |\n",
    "| `details` | Short explanation of what the test validates. |\n",
    "| `run_ts` | Timestamp when the test result row was inserted (default: current timestamp). |\n",
    "\n",
    "## Problems to Solve\n",
    "\n",
    "Implement a QA suite that inserts one row per test into `qa_db.test_results` for the current `test_run_id`.\n",
    "\n",
    "### 1) Bronze: Duplicate `order_id` Check\n",
    "- **Goal:** Detect `order_id` values that appear more than once in Bronze.\n",
    "- **Expected:** `0` duplicates.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n",
    "\n",
    "### 2) Silver: Null/Blank City Check\n",
    "- **Goal:** Ensure `city` is not NULL or blank after Silver standardization.\n",
    "- **Expected:** `0` rows with `city IS NULL OR TRIM(city) = ''`.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n",
    "\n",
    "Example Query:\n",
    "```sql\n",
    "INSERT INTO qa_db.test_results (test_run_id, test_name, status, actual_value, expected_desc, details)\n",
    "SELECT\n",
    "  @test_run_id,\n",
    "  'Silver: Beauty exclusion rule',\n",
    "  CASE WHEN COUNT(*) = 0 THEN 'PASS' ELSE 'FAIL' END,\n",
    "  COUNT(*),\n",
    "  '0 expected',\n",
    "  'Beauty rows should not be promoted to Silver'\n",
    "FROM silver_db.silver_sales_clean\n",
    "WHERE product_category = 'Beauty';\n",
    "```\n",
    "\n",
    "### 3) Silver: Beauty Products Exclusion Rule\n",
    "- **Goal:** Confirm that `product_category = 'Beauty'` does not exist in Silver.\n",
    "- **Expected:** `0` rows.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n",
    "\n",
    "### 4) Silver: Invalid Email Format Check\n",
    "- **Goal:** Identify invalid email values (example: `invalid-email`).\n",
    "- **Rule (simplified):** Email must contain both `@` and `.`.\n",
    "- **Expected:** `0` invalid emails.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n",
    "\n",
    "### 5) Gold Fact: `total_amount` Calculation Check\n",
    "- **Goal:** Validate `total_amount` matches `quantity * unit_price` within tolerance.\n",
    "- **Rule:** `ABS(total_amount - (quantity * unit_price)) <= 0.01`.\n",
    "- **Expected:** `0` mismatches.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n",
    "\n",
    "### 6) Completeness: Silver → Gold Missing `order_id` Check\n",
    "- **Goal:** Ensure every Silver `order_id` exists in Gold `fact_sales`.\n",
    "- **Rule:** Silver left join fact; count rows where `fact.order_id IS NULL`.\n",
    "- **Expected:** `0` missing order_ids.\n",
    "- **PASS/FAIL:** PASS if count = 0, else FAIL.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
